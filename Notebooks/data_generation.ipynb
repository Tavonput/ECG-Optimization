{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation From Preprocessed CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from Dataset.data_generation_csv import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Large Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_df = pd.read_csv(\"Data/mitbih_train.csv\", header=None)\n",
    "raw_test_df = pd.read_csv(\"Data/mitbih_test.csv\", header=None)\n",
    "\n",
    "x_train = raw_train_df.iloc[:, :-1]\n",
    "y_train = raw_train_df.iloc[:, -1]\n",
    "x_test  = raw_test_df.iloc[:, :-1]\n",
    "y_test  = raw_test_df.iloc[:, -1]\n",
    "\n",
    "smote = SMOTE(sampling_strategy={1: 30000, 2: 20000, 3: 20000, 4: 10000}, random_state=0)\n",
    "x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "training_data = {\n",
    "    \"features\": x_train,\n",
    "    \"labels\"  : y_train,\n",
    "}\n",
    "test_data = {\n",
    "    \"features\": x_test,\n",
    "    \"labels\"  : y_test,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_raw_ecg(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_data(\"Data/mitbih_mif_train.h5\", training_data, batch_size=5000)\n",
    "transform_data(\"Data/mitbih_mif_test.h5\", test_data, batch_size=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Small Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_df = pd.read_csv(\"Data/mitbih_train.csv\", header=None)\n",
    "\n",
    "training_data = {\n",
    "    \"features\": raw_train_df.iloc[60000:, :-1],\n",
    "    \"labels\"  : raw_train_df.iloc[60000:, -1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_data(\"Data/mitbih_mif_train_small.h5\", training_data, batch_size=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Calibration Datasets For Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_frame(df, save_path):\n",
    "    training_data = {\n",
    "        \"features\": df.iloc[:, :-1],\n",
    "        \"labels\":   df.iloc[:, -1]\n",
    "    }\n",
    "    transform_data(save_path, training_data, batch_size=1000)\n",
    "\n",
    "\n",
    "def class_distribution(df):\n",
    "    print(df.value_counts(normalize=True))\n",
    "\n",
    "n_samples = 3200\n",
    "\n",
    "# Original dataset\n",
    "print(\"Original dataset class distribution\")\n",
    "raw_train_df = pd.read_csv(\"Data/mitbih_train.csv\", header=None)\n",
    "class_distribution(raw_train_df[187])\n",
    "print()\n",
    "\n",
    "# Random sample\n",
    "random_sample = raw_train_df.sample(n=n_samples, random_state=1)\n",
    "print(\"Processing random sample calibration set\")\n",
    "class_distribution(random_sample[187])\n",
    "process_data_frame(random_sample, \"Data/mitbih_calib_random.h5\")\n",
    "print()\n",
    "\n",
    "# Balanced dataset\n",
    "labels_df = []\n",
    "for label in range(5):\n",
    "    label_filtered_df = raw_train_df[raw_train_df[187] == label]\n",
    "    labels_df.append(label_filtered_df.sample(n=(n_samples//5), random_state=1))\n",
    "\n",
    "balanced_sample = pd.concat(labels_df, ignore_index=True)\n",
    "print(\"Processing balanced sample calibration set\")\n",
    "class_distribution(balanced_sample[187])\n",
    "process_data_frame(random_sample, \"Data/mitbih_calib_balanced.h5\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation From Raw Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from Dataset.data_generation import create_raw_dataset, create_image_dataset, create_train_test_from_dataset\n",
    "\n",
    "window_size = 128\n",
    "batch_size  = 2000\n",
    "\n",
    "# Raw signal dataset\n",
    "data_path  = \"../Data/MIT-BIH-Raw/mit-bih-arrhythmia-database-1.0.0\"\n",
    "raw_path   = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-{window_size}/signal_full_unfiltered_i{window_size}.h5\"\n",
    "\n",
    "create_raw_dataset(data_path, raw_path, window_size, full=True)\n",
    "create_train_test_from_dataset(\n",
    "    dataset_path = raw_path,\n",
    "    output_name  = f\"signal_full_unfiltered_i{window_size}\",\n",
    "    ratio        = 0.8,\n",
    "    data_key     = \"segments\",\n",
    "    shuffle      = True,\n",
    "    batch_size   = batch_size\n",
    ")\n",
    "\n",
    "# Image datasets\n",
    "for split in [\"train\", \"test\"]:\n",
    "    create_image_dataset(\n",
    "        signal_dataset_path = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-{window_size}/signal_full_unfiltered_i{window_size}_{split}.h5\", \n",
    "        output_path         = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-{window_size}/image_full_unfiltered_i{window_size}_{split}.h5\",\n",
    "        batch_size          = batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from Dataset.data_generation import create_image_dataset_contiguous\n",
    "\n",
    "window_sizes = [256, 224, 192, 160]\n",
    "batch_size  = 1000\n",
    "\n",
    "# Raw sets and train split are already created\n",
    "\n",
    "# Image datasets\n",
    "for window_size in window_sizes:\n",
    "    create_image_dataset_contiguous(\n",
    "        signal_dataset_path = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-{window_size}/signal_unfiltered_i{window_size}_train.h5\", \n",
    "        output_path         = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-{window_size}/image_unfiltered_i{window_size}_train.h5\",\n",
    "        batch_size          = batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from Dataset.data_generation import create_image_dataset_contiguous\n",
    "\n",
    "create_image_dataset_contiguous(\n",
    "    signal_dataset_path = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-256/signal_unfiltered_i256_test.h5\", \n",
    "    output_path         = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-256/image_unfiltered_i256_test.h5\",\n",
    "    batch_size          = 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanced vs Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from Dataset.data_generation import create_subset_from_dataset, create_image_dataset\n",
    "\n",
    "for ratio in [0.7, 0.6, 0.5, 0.4, 0.3]:\n",
    "    for method in [\"balance\", \"random\"]:\n",
    "        create_subset_from_dataset(\n",
    "            dataset_path = \"../Data/MIT-BIH-Raw/Datasets/Resolution-128/signal_unfiltered_i128_train.h5\",\n",
    "            output_name  = f\"signal_unfiltered_i128_train_r{ratio}_{method}\",\n",
    "            data_key     = \"segments\",\n",
    "            method       = method,\n",
    "            ratio        = ratio,\n",
    "            shuffle      = False, # Base dataset is already shuffled\n",
    "            batch_size   = 5000\n",
    "        )\n",
    "        create_image_dataset(\n",
    "            signal_dataset_path = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-128/signal_unfiltered_i128_train_r{ratio}_{method}.h5\",\n",
    "            output_path         = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-128/image_unfiltered_i128_train_r{ratio}_{method}.h5\",\n",
    "            batch_size          = 5000\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import h5py\n",
    "\n",
    "from Dataset.data_generation import get_class_distribution\n",
    "\n",
    "norm = False\n",
    "with h5py.File(\"../Data/MIT-BIH-Raw/Datasets/Resolution-128/image_unfiltered_i128_train.h5\", \"r\") as hdf:\n",
    "    labels = hdf[\"labels\"][:]\n",
    "    print(f\"Base:         {len(labels)}, {get_class_distribution(labels, normalize=norm)}\")\n",
    "\n",
    "for ratio in [0.7, 0.6, 0.5, 0.4, 0.3]:\n",
    "    with h5py.File(f\"../Data/MIT-BIH-Raw/Datasets/Resolution-128/image_unfiltered_i128_train_r{ratio}_balance.h5\", \"r\") as hdf:\n",
    "        labels = hdf[\"labels\"][:]\n",
    "        print(f\"Balanced {ratio}: {len(labels)}, {get_class_distribution(labels, normalize=norm)}\")\n",
    "\n",
    "    with h5py.File(f\"../Data/MIT-BIH-Raw/Datasets/Resolution-128/image_unfiltered_i128_train_r{ratio}_random.h5\", \"r\") as hdf:\n",
    "        labels = hdf[\"labels\"][:]\n",
    "        print(f\"Random   {ratio}: {len(labels)}, {get_class_distribution(labels, normalize=norm)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from Dataset.data_generation import create_subset_from_dataset, create_image_dataset, create_raw_dataset, create_train_test_from_dataset\n",
    "\n",
    "data_path   = \"../Data/MIT-BIH-Raw/mit-bih-arrhythmia-database-1.0.0\"\n",
    "batch_size  = 1000\n",
    "set_configs = [(248, 0.3), (232, 0.3), (216, 0.4), (200, 0.4), (184, 0.4), (168, 0.5), (152, 0.6), (136, 0.6)]\n",
    "\n",
    "for window_size, ratio in set_configs:\n",
    "    raw_path = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-{window_size}/signal_unfiltered_i{window_size}.h5\"\n",
    "\n",
    "    # Raw\n",
    "    create_raw_dataset(data_path, raw_path, window_size)\n",
    "\n",
    "    # Train-test\n",
    "    create_train_test_from_dataset(\n",
    "        dataset_path = raw_path,\n",
    "        output_name  = f\"signal_unfiltered_i{window_size}\",\n",
    "        ratio        = 0.8,\n",
    "        data_key     = \"segments\",\n",
    "        shuffle      = True,\n",
    "        batch_size   = batch_size\n",
    "    )\n",
    "    for method in [\"balance\"]:\n",
    "        # Subset\n",
    "        create_subset_from_dataset(\n",
    "            dataset_path = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-{window_size}/signal_unfiltered_i{window_size}_train.h5\",\n",
    "            output_path  = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-{window_size}/signal_unfiltered_i{window_size}_train_r{ratio}_{method}.h5\",\n",
    "            data_key     = \"segments\",\n",
    "            method       = method,\n",
    "            ratio        = ratio,\n",
    "            shuffle      = False, # Base dataset is already shuffled\n",
    "            batch_size   = batch_size\n",
    "        )\n",
    "\n",
    "        # Image train\n",
    "        create_image_dataset(\n",
    "            signal_dataset_path = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-{window_size}/signal_unfiltered_i{window_size}_train_r{ratio}_{method}.h5\",\n",
    "            output_path         = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-{window_size}/image_unfiltered_i{window_size}_train_r{ratio}_{method}.h5\",\n",
    "            batch_size          = batch_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from Dataset.data_generation import create_raw_dataset, create_image_dataset, create_train_test_from_dataset\n",
    "\n",
    "window_size = 64\n",
    "batch_size  = 1000\n",
    "\n",
    "# Raw signal dataset\n",
    "data_path  = \"../Data/MIT-BIH-Raw/mit-bih-arrhythmia-database-1.0.0\"\n",
    "raw_path   = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-{window_size}/signal_unfiltered_i{window_size}.h5\"\n",
    "\n",
    "create_raw_dataset(data_path, raw_path, window_size)\n",
    "create_train_test_from_dataset(\n",
    "    dataset_path = raw_path,\n",
    "    output_name  = f\"signal_unfiltered_i{window_size}\",\n",
    "    ratio        = 0.8,\n",
    "    data_key     = \"segments\",\n",
    "    shuffle      = True,\n",
    "    batch_size   = batch_size\n",
    ")\n",
    "\n",
    "# Image datasets\n",
    "for split in [\"train\", \"test\"]:\n",
    "    create_image_dataset(\n",
    "        signal_dataset_path = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-{window_size}/signal_unfiltered_i{window_size}_{split}.h5\", \n",
    "        output_path         = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-{window_size}/image_unfiltered_i{window_size}_{split}.h5\",\n",
    "        batch_size          = batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downscale And Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from Dataset.data_generation import create_raw_dataset, create_image_dataset, create_train_test_from_dataset, create_preprocessed_dataset\n",
    "\n",
    "data_path  = \"../Data/MIT-BIH-Raw/mit-bih-arrhythmia-database-1.0.0\"\n",
    "batch_size = 1000\n",
    "\n",
    "original_size = 256\n",
    "new_size      = 128\n",
    "\n",
    "# Create the base raw datasets first\n",
    "create_raw_dataset(\n",
    "    data_path   = data_path, \n",
    "    output_path = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-{original_size}/signal_unfiltered_i{original_size}.h5\", \n",
    "    window_size = original_size\n",
    ")\n",
    "create_train_test_from_dataset(\n",
    "    dataset_path = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-{original_size}/signal_unfiltered_i{original_size}.h5\",\n",
    "    output_name  = f\"signal_unfiltered_i{original_size}\",\n",
    "    ratio        = 0.8,\n",
    "    data_key     = \"segments\",\n",
    "    shuffle      = True,\n",
    "    batch_size   = batch_size\n",
    ")\n",
    "for split in [\"train\", \"test\"]:\n",
    "    create_image_dataset(\n",
    "        signal_dataset_path = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-{original_size}/signal_unfiltered_i{original_size}_{split}.h5\", \n",
    "        output_path         = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-{original_size}/image_unfiltered_i{original_size}_{split}.h5\",\n",
    "        batch_size          = batch_size\n",
    "    )\n",
    "\n",
    "for method in [\"resize\", \"crop\"]:\n",
    "    for split in [\"train\", \"test\"]:\n",
    "        create_preprocessed_dataset(\n",
    "            dataset_path = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-{original_size}/image_unfiltered_i{original_size}_{split}.h5\",\n",
    "            output_path  = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-{new_size}/image_{method}_i{new_size}_{split}.h5\",\n",
    "            data_key     = \"images\",\n",
    "            method       = method,\n",
    "            new_size     = new_size,\n",
    "            batch_size   = batch_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from Dataset.data_generation import create_subset_from_dataset, create_image_dataset\n",
    "\n",
    "data_path  = \"../Data/MIT-BIH-Raw/mit-bih-arrhythmia-database-1.0.0\"\n",
    "batch_size = 1000\n",
    "\n",
    "original_size = 256\n",
    "config = [(256, 0.3)]\n",
    "# config = [(256, 0.3), (224, 0.3), (192, 0.4), (160, 0.5)]\n",
    "\n",
    "for resolution, ratio in config:\n",
    "    create_subset_from_dataset(\n",
    "        dataset_path = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-{original_size}/signal_unfiltered_i{original_size}_train.h5\",\n",
    "        output_path  = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-{original_size}/signal_unfiltered_i{original_size}_train_r{ratio}.h5\",\n",
    "        data_key     = \"segments\",\n",
    "        method       = \"balance\",\n",
    "        ratio        = ratio,\n",
    "        shuffle      = True,\n",
    "        batch_size   = batch_size\n",
    "    )\n",
    "\n",
    "    if resolution == original_size:\n",
    "        create_image_dataset(\n",
    "            signal_dataset_path = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-{original_size}/signal_unfiltered_i{original_size}_train_r{ratio}.h5\",\n",
    "            output_path         = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-{resolution}/image_resize_i{resolution}_train_r{ratio}.h5\",\n",
    "            batch_size          = batch_size,\n",
    "        )\n",
    "    else:\n",
    "        create_image_dataset(\n",
    "            signal_dataset_path = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-{original_size}/signal_unfiltered_i{original_size}_train_r{ratio}.h5\",\n",
    "            output_path         = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-{resolution}/image_resize_i{resolution}_train_r{ratio}.h5\",\n",
    "            batch_size          = batch_size,\n",
    "            preprocess          = \"resize\",\n",
    "            new_size            = resolution\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_image(images: dict[str, np.ndarray]) -> None:\n",
    "    _, axs = plt.subplots(3, 3, figsize=(10, 10))\n",
    "    for i, (name, img_chw) in enumerate(images.items()):\n",
    "        for j, img_hw in enumerate(img_chw):\n",
    "            axs[i, j].imshow(img_hw)\n",
    "            axs[i, j].axis(False)\n",
    "        axs[i, 0].set_ylabel(name)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "image_idx = 100\n",
    "images = dict()\n",
    "with h5py.File(\"../Data/MIT-BIH-Raw/Datasets/Resolution-128/image_unfiltered_i128_train.h5\", \"r\") as hdf:\n",
    "    images[\"Normal\"] = hdf[\"images\"][image_idx]\n",
    "    \n",
    "with h5py.File(\"../Data/MIT-BIH-Raw/Datasets/Resolution-128/image_resize_i128_train.h5\", \"r\") as hdf:\n",
    "    images[\"Downscale\"] = hdf[\"images\"][image_idx]\n",
    "\n",
    "with h5py.File(\"../Data/MIT-BIH-Raw/Datasets/Resolution-128/image_crop_i128_train.h5\", \"r\") as hdf:\n",
    "    images[\"Center Crop\"] = hdf[\"images\"][image_idx]\n",
    "\n",
    "visualize_image(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_raw_signal(signal: np.ndarray) -> None:\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_palette(\"husl\")\n",
    "\n",
    "    _, ax = plt.subplots(figsize=(10, 4))\n",
    "    ax.plot(signal)\n",
    "    ax.axis(False)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "with h5py.File(\"../Data/MIT-BIH-Raw/Datasets/Resolution-256/signal_unfiltered_i256_train.h5\", \"r\") as hdf:\n",
    "    signal = hdf[\"segments\"][100]\n",
    "    plot_raw_signal(signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from Dataset.data_generation import create_full_split_sets, create_image_dataset_contiguous\n",
    "\n",
    "batch_size  = 1000\n",
    "set_configs = [(256, 4), (224, 3), (192, 2), (160, 2)]\n",
    "\n",
    "for res, num_subsets in set_configs:\n",
    "    create_full_split_sets(\n",
    "        dataset_path = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-{res}/signal_unfiltered_i{res}_train.h5\",\n",
    "        output_dir   = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-{res}/unfiltered_i{res}_train_full_split_{num_subsets}\",\n",
    "        data_key     = \"segments\",\n",
    "        num_sets     = num_subsets,\n",
    "        shuffle      = False, # Base dataset is already shuffled\n",
    "        batch_size   = batch_size\n",
    "    )\n",
    "    for i in range(num_subsets):\n",
    "        create_image_dataset_contiguous(\n",
    "            signal_dataset_path = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-{res}/unfiltered_i{res}_train_full_split_{num_subsets}/set_{i}.h5\",\n",
    "            output_path         = f\"../Data/MIT-BIH-Raw/Datasets/Resolution-{res}/unfiltered_i{res}_train_full_split_{num_subsets}/image_set_{i}.h5\",\n",
    "            batch_size          = batch_size\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
